{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPnqiAn9N2mKZvCvt4d9TC8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShannonH98/PyTorch_Practice_Projects/blob/main/MNIST_Digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST Digits"
      ],
      "metadata": {
        "id": "KOawgHtt7XUM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFQtSSc5zvpP"
      },
      "outputs": [],
      "source": [
        "#Import torch\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# Import torchvision\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn, optim\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "#ToTensor can take image data and turn it into tensor data\n",
        "# Import matplotlib for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check versions\n",
        "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True, #we want the training data set\n",
        "    download=True, #we want to download\n",
        "    transform=ToTensor(), #need to convert to tensor to be able to use it\n",
        "    target_transform=None #do we want to transform the target/labels\n",
        ")\n",
        "\n",
        "#now do the same to test data\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True, #we want to download\n",
        "    transform=ToTensor(), #need to convert to tensor to be able to use it\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "#This section dowloads the data needed for this model"
      ],
      "metadata": {
        "id": "F_CQXq9e9GSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "ysSw6yae9iSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "id": "DPaWTxb_9kQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_data), len(train_data)"
      ],
      "metadata": {
        "id": "iR0S3eobgY0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "k4ceyZRRZyOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_to_idx = train_data.class_to_idx\n",
        "class_to_idx"
      ],
      "metadata": {
        "id": "lufDkbnnZ0pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = 32\n",
        "#turn imported dataset into a data loader\n",
        "#reducing the amount of data to start with\n",
        "train_loader = DataLoader(dataset=train_data,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_data,\n",
        "                         batch_size=batch_size)\n",
        "\n",
        "print(f\"Dataloaders: {train_loader, test_loader}\")\n",
        "print(f\"Length of train dataloader: {len(train_loader)} batches of {batch_size}\")\n",
        "print(f\"Length of test dataloader: {len(test_loader)} batches of {batch_size}\")"
      ],
      "metadata": {
        "id": "bp3n1MwkZOYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yY8ABBnqcp72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[0]\n",
        "image, label"
      ],
      "metadata": {
        "id": "IRoBqZIqaQQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape, label"
      ],
      "metadata": {
        "id": "iLOlcz2bZ4iM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#color channel of 1, then height and width"
      ],
      "metadata": {
        "id": "8s0qJhIKhDcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = next(iter(train_loader)) #iterates through the train data loader\n",
        "\n",
        "print(\"Images shape:\", image.shape)\n",
        "print(\"Images type:\", image.dtype)\n",
        "print(\"Labels shape:\", label.shape)\n",
        "print(\"Labels type:\", label.dtype)"
      ],
      "metadata": {
        "id": "LRAThOusZVfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names[label[0]]"
      ],
      "metadata": {
        "id": "sMnXp3qZaaei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing the Data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image, label = train_data[0]#first value\n",
        "print(f\"Image shape: {image.shape}\")\n",
        "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
        "plt.title(label);"
      ],
      "metadata": {
        "id": "qpsYDONWayCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.manual_seed(42)\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "rows, cols = 4,4\n",
        "for i in range(1, rows*cols+1):\n",
        "\n",
        "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
        "    fig.add_subplot(rows, cols, i)\n",
        "    image, label = train_data[random_idx]\n",
        "    plt.imshow(image.squeeze(), cmap=\"gray\")\n",
        "    plt.title(class_names[label])\n",
        "    plt.axis(False);"
      ],
      "metadata": {
        "id": "NC9MSH8nbBjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_batch, train_labels_batch = next(iter(train_loader))\n",
        "train_features_batch.shape, train_labels_batch.shape"
      ],
      "metadata": {
        "id": "L8x1B0HOb6rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
        "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[label])\n",
        "plt.axis(\"Off\");\n",
        "print(f\"Image size: {img.shape}\")\n",
        "print(f\"Label: {label}, label size: {label.shape}\")"
      ],
      "metadata": {
        "id": "aCMjQrBtb6pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flatten_model = nn.Flatten()\n",
        "\n",
        "x = train_features_batch[0] #forward pass gets performed\n",
        "\n",
        "#Flatten the sample\n",
        "output = flatten_model(x)\n",
        "print(f\"Shape before flattening: {x.shape} -> [color_channels, height, width]\")\n",
        "print(f\"Shape after flattening: {output.shape} -> [color_channels, height*width]\")"
      ],
      "metadata": {
        "id": "hg71fYUbb6mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class DigitClassifierv1(nn.Module):\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.layer_stack = nn.Sequential(\n",
        "            nn.Flatten(), # neural networks like their inputs in vector form\n",
        "            nn.Linear(in_features=input_shape, out_features=hidden_units), # in_features = number of features in a data sample (784 pixels)\n",
        "            nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "      return self.layer_stack(x)\n"
      ],
      "metadata": {
        "id": "ze_Nnlqgb6kJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model_0 = DigitClassifierv1(\n",
        "    input_shape=784,#result of the flatten layer\n",
        "    hidden_units=10,\n",
        "    output_shape=len(class_names)\n",
        ")\n",
        "model_0\n"
      ],
      "metadata": {
        "id": "oeMj5TN3b6h5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_x = torch.rand([1,1,28,28]) #batch, color channel, height, width\n",
        "model_0(dummy_x).shape"
      ],
      "metadata": {
        "id": "tlq5hBwOb6fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.py already exists, skipping download\")\n",
        "else:\n",
        "  print(\"Downloading helper_functions.py\")\n",
        "  # Note: you need the \"raw\" GitHub URL for this to work\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)"
      ],
      "metadata": {
        "id": "7ol9jF7Vb6dC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the previously built accuracy function\n",
        "from helper_functions import accuracy_fn\n",
        "\n",
        "#setup loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "zLr9NQJdb6aU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Track speed\n",
        "from timeit import default_timer as timer\n",
        "def print_train_time(start: float,\n",
        "                     end: float,\n",
        "                     device: torch.device = None):\n",
        "    \"\"\"Prints difference between start and end time.\"\"\"\n",
        "    total_time = end - start\n",
        "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
        "    return total_time\n",
        "\n"
      ],
      "metadata": {
        "id": "9g48yUs9b57J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = timer()\n",
        "\n",
        "end_time = timer()\n",
        "print_train_time(start=start_time, end=end_time, device=None)"
      ],
      "metadata": {
        "id": "Ju16IwWbfSp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm #progress bar\n",
        "\n",
        "#Set the seed and start the timer\n",
        "\n",
        "torch.manual_seed(42)\n",
        "train_time_start_on_cpu = timer()\n",
        "\n",
        "#set the number of epochs (we'll keep this small for faster training time)\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "#create training and test loop\n",
        "\n",
        "for epochs in tqdm(range(epochs)):\n",
        "    print(f\"Epoch: {epochs}\\n-------\")\n",
        "\n",
        "    ###Training\n",
        "    train_loss = 0\n",
        "\n",
        "    # Add a loop to loop through training batches\n",
        "    for batch, (X, y) in enumerate(train_loader):\n",
        "        model_0.train()\n",
        "        # 1. Forward pass\n",
        "        y_pred = model_0(X)\n",
        "\n",
        "        # 2. Calculate loss (per batch)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss # accumulatively add up the loss per epoch\n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print out how many samples have been seen\n",
        "        if batch % 400 == 0:\n",
        "            print(f\"Viewed {batch * len(X)}/{len(train_loader.dataset)} samples\")\n",
        "\n",
        "    #Divide total train loss by lenght of train loader\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    ### Testing\n",
        "    # Setup variables for accumulatively adding up loss and accuracy\n",
        "    test_loss, test_acc = 0, 0\n",
        "    model_0.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in test_loader:\n",
        "            # 1. Forward pass\n",
        "            test_pred = model_0(X)\n",
        "\n",
        "            # 2. Calculate loss (accumulatively)\n",
        "            test_loss += loss_fn(test_pred, y) # accumulatively add up the loss per epoch\n",
        "\n",
        "            # 3. Calculate accuracy (preds need to be same as y_true)\n",
        "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "        # Calculations on test metrics need to happen inside torch.inference_mode()\n",
        "        # Divide total test loss by length of test dataloader (per batch)\n",
        "        test_loss /= len(test_loader)\n",
        "\n",
        "        # Divide total accuracy by length of test dataloader (per batch)\n",
        "        test_acc /= len(test_loader)\n",
        "\n",
        "    ## Print out what's happening\n",
        "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n",
        "\n",
        "# Calculate training time\n",
        "train_time_end_on_cpu = timer()\n",
        "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,\n",
        "                                           end=train_time_end_on_cpu,\n",
        "                                           device=str(next(model_0.parameters()).device))"
      ],
      "metadata": {
        "id": "SbJKE-4rfmV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn):\n",
        "    \"return a dictionary of model prediciton results \"\n",
        "    loss, acc = 0, 0\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in tqdm(data_loader):\n",
        "            # Make predictions with the model\n",
        "            y_pred = model(X)\n",
        "\n",
        "            # Accumulate the loss and accuracy values per batch\n",
        "            loss += loss_fn(y_pred, y)\n",
        "            acc += accuracy_fn(y_true=y,\n",
        "                                y_pred=y_pred.argmax(dim=1)) # For accuracy, need the prediction labels (logits -> pred_prob -> pred_labels)\n",
        "\n",
        "        # Scale loss and acc to find the average loss/acc per batch\n",
        "        loss /= len(data_loader)\n",
        "        acc /= len(data_loader)\n",
        "\n",
        "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
        "            \"model_loss\": loss.item(),\n",
        "            \"model_acc\": acc}\n",
        "\n",
        "# Calculate model 0 results on test dataset\n",
        "model_0_results = eval_model(model=model_0, data_loader=test_loader,\n",
        "    loss_fn=loss_fn, accuracy_fn=accuracy_fn\n",
        ")\n",
        "model_0_results"
      ],
      "metadata": {
        "id": "a48Q-PdAjUEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 2"
      ],
      "metadata": {
        "id": "INRwiI6S6_yI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DigitClassifierv2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DigitClassifierv2, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 128)  # Input layer to hidden layer\n",
        "        self.fc2 = nn.Linear(128, 10)     # Hidden layer to 10 output classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)  # Flatten the image\n",
        "        x = F.relu(self.fc1(x))  # Apply ReLU activation\n",
        "        return self.fc2(x)  # Output logits for 10 digits\n",
        "\n"
      ],
      "metadata": {
        "id": "78DyDGgWXEAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model_1 = DigitClassifierv2()\n",
        "model_1"
      ],
      "metadata": {
        "id": "g_DQGQMEHtXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_1.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "eFh18E3AXF4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "from tqdm.auto import tqdm\n",
        "torch.manual_seed(42)\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "train_time_start_on_cpu = timer()\n",
        "for epochs in tqdm(range(epochs)):  # Train for 3 epochs\n",
        "  print(f\"Epoch: {epochs}\\n-------\")\n",
        "  for images, labels in train_loader:\n",
        "    outputs = model_1(images)  # Forward pass\n",
        "    loss = criterion(outputs, labels)  # Compute loss\n",
        "\n",
        "    optimizer.zero_grad()  # Clear gradients\n",
        "    loss.backward()        # Backpropagation\n",
        "    optimizer.step()       # Update weights\n",
        "\n",
        "    #print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')\n",
        "    #print(f\"Viewed {batch * len(X)}/{len(train_loader.dataset)} samples\")\n",
        "# Evaluate model accuracy on test data\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():  # Disable gradient calculation for testing\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model_1(images)\n",
        "        _, predicted = torch.max(outputs, 1)  # Get class with highest score\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
        "\n",
        "acc2 = 100 * correct / total\n",
        "\n",
        "\n",
        "train_time_end_on_cpu = timer()\n",
        "total_train_time_model_1 = print_train_time(start=train_time_start_on_cpu,\n",
        "                                           end=train_time_end_on_cpu,\n",
        "                                           device=str(next(model_1.parameters()).device))"
      ],
      "metadata": {
        "id": "OagL0KDrXINB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn):\n",
        "    \"return a dictionary of model prediciton results \"\n",
        "    loss, acc = 0, 0\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in tqdm(data_loader):\n",
        "            # Make predictions with the model\n",
        "            y_pred = model(X)\n",
        "\n",
        "            # Accumulate the loss and accuracy values per batch\n",
        "            loss += loss_fn(y_pred, y)\n",
        "            acc += accuracy_fn(y_true=y,\n",
        "                                y_pred=y_pred.argmax(dim=1)) # For accuracy, need the prediction labels (logits -> pred_prob -> pred_labels)\n",
        "\n",
        "        # Scale loss and acc to find the average loss/acc per batch\n",
        "        loss /= len(data_loader)\n",
        "        acc /= len(data_loader)\n",
        "\n",
        "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
        "            \"model_loss\": loss.item(),\n",
        "            \"model_acc\": acc2}\n",
        "\n",
        "# Calculate model 1 results on test dataset\n",
        "model_1_results = eval_model(model=model_1, data_loader=test_loader,\n",
        "    loss_fn=loss_fn, accuracy_fn=accuracy_fn\n",
        ")\n",
        "model_1_results"
      ],
      "metadata": {
        "id": "E0c9kQkAHVf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 3"
      ],
      "metadata": {
        "id": "oFrEvQ2VDKlj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "xGSPV5H8EZ3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DigitClassifierv3(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_shape: int,\n",
        "                 hidden_units: int,\n",
        "                 output_shape: int):\n",
        "        super(DigitClassifierv3, self).__init__()\n",
        "        self.layer_stack = nn.Sequential(\n",
        "            nn.Flatten(), # neural networks like their inputs in vector form\n",
        "            nn.Linear(in_features=input_shape, out_features=hidden_units), # in_features = number of features in a data sample (784 pixels)\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        return self.layer_stack(x)"
      ],
      "metadata": {
        "id": "GxzA6SS6DLxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model_2 = DigitClassifierv3(input_shape = 784,\n",
        "                            hidden_units = 0,\n",
        "                            output_shape =len(class_names))\n",
        "model_2"
      ],
      "metadata": {
        "id": "-6VzEyjBD4kB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2"
      ],
      "metadata": {
        "id": "QAUw36tWEzgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(model_2.parameters()).device"
      ],
      "metadata": {
        "id": "Ql3gmJlbE1pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import accuracy_fn\n",
        "\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_2.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "oTv5x4ItFKkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm #progress bar\n",
        "\n",
        "#Set the seed and start the timer\n",
        "\n",
        "torch.manual_seed(42)\n",
        "train_time_start_on_cpu = timer()\n",
        "\n",
        "#set the number of epochs (we'll keep this small for faster training time)\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "#create training and test loop\n",
        "\n",
        "for epochs in tqdm(range(epochs)):\n",
        "    print(f\"Epoch: {epochs}\\n-------\")\n",
        "\n",
        "    ###Training\n",
        "    train_loss = 0\n",
        "\n",
        "    # Add a loop to loop through training batches\n",
        "    for batch, (X, y) in enumerate(train_loader):\n",
        "        model_2.train()\n",
        "        # 1. Forward pass\n",
        "        y_pred = model_2(X)\n",
        "\n",
        "        # 2. Calculate loss (per batch)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss # accumulatively add up the loss per epoch\n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print out how many samples have been seen\n",
        "        if batch % 400 == 0:\n",
        "            print(f\"Viewed {batch * len(X)}/{len(train_loader.dataset)} samples\")\n",
        "\n",
        "    #Divide total train loss by lenght of train loader\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    ### Testing\n",
        "    # Setup variables for accumulatively adding up loss and accuracy\n",
        "    test_loss, test_acc = 0, 0\n",
        "    model_2.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in test_loader:\n",
        "            # 1. Forward pass\n",
        "            test_pred = model_2(X)\n",
        "\n",
        "            # 2. Calculate loss (accumulatively)\n",
        "            test_loss += loss_fn(test_pred, y) # accumulatively add up the loss per epoch\n",
        "\n",
        "            # 3. Calculate accuracy (preds need to be same as y_true)\n",
        "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "\n",
        "        test_loss /= len(test_loader)\n",
        "\n",
        "        # Divide total accuracy by length of test dataloader (per batch)\n",
        "        test_acc /= len(test_loader)\n",
        "\n",
        "    ## Print out what's happening\n",
        "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc}%\\n\")\n",
        "\n",
        "# Calculate training time\n",
        "train_time_end_on_cpu = timer()\n",
        "total_train_time_model_2 = print_train_time(start=train_time_start_on_cpu,\n",
        "                                           end=train_time_end_on_cpu,\n",
        "                                           device=str(next(model_2.parameters()).device))"
      ],
      "metadata": {
        "id": "0_XTI2wDFry1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn):\n",
        "    \"return a dictionary of model prediciton results \"\n",
        "    loss, acc = 0, 0\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in tqdm(data_loader):\n",
        "            # Make predictions with the model\n",
        "            y_pred = model(X)\n",
        "\n",
        "            # Accumulate the loss and accuracy values per batch\n",
        "            loss += loss_fn(y_pred, y)\n",
        "            acc += accuracy_fn(y_true=y,\n",
        "                                y_pred=y_pred.argmax(dim=1)) # For accuracy, need the prediction labels (logits -> pred_prob -> pred_labels)\n",
        "\n",
        "        # Scale loss and acc to find the average loss/acc per batch\n",
        "        loss /= len(data_loader)\n",
        "        acc /= len(data_loader)\n",
        "\n",
        "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
        "            \"model_loss\": loss.item(),\n",
        "            \"model_acc\": acc}\n",
        "\n",
        "# Calculate model 2 results on test dataset\n",
        "model_2_results = eval_model(model=model_2, data_loader=test_loader,\n",
        "    loss_fn=loss_fn, accuracy_fn=accuracy_fn\n",
        ")\n",
        "model_2_results"
      ],
      "metadata": {
        "id": "sSjyo3FLKRyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_results, model_1_results,model_2_results"
      ],
      "metadata": {
        "id": "bXo-r67aMnlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "compare_results = pd.DataFrame([model_0_results, model_1_results,model_2_results])\n",
        "compare_results"
      ],
      "metadata": {
        "id": "7bk1bmHqRAuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_results[\"training_time\"] = [total_train_time_model_0, total_train_time_model_1,total_train_time_model_2]\n",
        "compare_results"
      ],
      "metadata": {
        "id": "3ShppdqqRlZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize\n",
        "compare_results.plot.bar(x=\"model_name\", y=\"model_acc\", rot=0)\n",
        "plt.savefig(\"model_acc_plot.png\")\n",
        "plt.ylabel(\"Accuracy of Model in %\")\n",
        "plt.xlabel(\"Model Name\")"
      ],
      "metadata": {
        "id": "SDpEcBxHRrxd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}